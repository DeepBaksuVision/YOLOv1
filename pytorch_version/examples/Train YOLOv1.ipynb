{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train YOLOv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T04:38:14.206863Z",
     "start_time": "2018-09-05T04:38:13.620185Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from torchsummary.torchsummary import summary\n",
    "from dataloader import VOC\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yolov1\n",
    "from yolov1 import detection_collate\n",
    "from yolov1 import detection_loss\n",
    "from yolov1 import save_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T04:38:14.206863Z",
     "start_time": "2018-09-05T04:38:13.620185Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convolutional neural network (two convolutional layers)\n",
    "class YOLOv1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(YOLOv1, self).__init__()\n",
    "        # LAYER 1\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(64), #, momentum=0.01\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        # LAYER 2\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 192, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(192, momentum=0.01),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        # LAYER 3\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(192, 128, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(128, momentum=0.01),\n",
    "            nn.LeakyReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256, momentum=0.01),\n",
    "            nn.LeakyReLU())\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=1, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256, momentum=0.01),\n",
    "            nn.LeakyReLU())\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(512, momentum=0.01),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        # LAYER 4\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(256, momentum=0.01),\n",
    "            nn.LeakyReLU())\n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512, momentum=0.01),\n",
    "            nn.LeakyReLU())\n",
    "        self.layer9 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(256, momentum=0.01),\n",
    "            nn.LeakyReLU())\n",
    "        self.layer10 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512, momentum=0.01),\n",
    "            nn.LeakyReLU())\n",
    "        self.layer11 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(256, momentum=0.01),\n",
    "            nn.LeakyReLU())\n",
    "        self.layer12 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512, momentum=0.01),\n",
    "            nn.LeakyReLU())\n",
    "        self.layer13 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(256, momentum=0.01),\n",
    "            nn.LeakyReLU())\n",
    "        self.layer14 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512, momentum=0.01),\n",
    "            nn.LeakyReLU())\n",
    "        self.layer15 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(512, momentum=0.01),\n",
    "            nn.LeakyReLU())\n",
    "        self.layer16 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(1024, momentum=0.01),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        # LAYER 5\n",
    "        self.layer17 = nn.Sequential(\n",
    "            nn.Conv2d(1024, 512, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(512, momentum=0.01),\n",
    "            nn.LeakyReLU())\n",
    "        self.layer18 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(1024, momentum=0.01),\n",
    "            nn.LeakyReLU())\n",
    "        self.layer19 = nn.Sequential(\n",
    "            nn.Conv2d(1024, 512, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(512, momentum=0.01),\n",
    "            nn.LeakyReLU())\n",
    "        self.layer20 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(1024, momentum=0.01),\n",
    "            nn.LeakyReLU())\n",
    "        self.layer21 = nn.Sequential(\n",
    "            nn.Conv2d(1024, 1024, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(1024, momentum=0.01),\n",
    "            nn.LeakyReLU())\n",
    "        self.layer22 = nn.Sequential(\n",
    "            nn.Conv2d(1024, 1024, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(1024, momentum=0.01),\n",
    "            nn.LeakyReLU())\n",
    "\n",
    "        # LAYER 6\n",
    "        self.layer23 = nn.Sequential(\n",
    "            nn.Conv2d(1024, 1024, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(1024, momentum=0.01),\n",
    "            nn.LeakyReLU())\n",
    "        self.layer24 = nn.Sequential(\n",
    "            nn.Conv2d(1024, 1024, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(1024, momentum=0.01),\n",
    "            nn.LeakyReLU())\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(7*7*1024, 4096),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout_prop)\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(4096, 7*7*((5)+num_classes)),\n",
    "            nn.Dropout(dropout_prop),\n",
    "        )\n",
    "\n",
    "\n",
    "        for m in self.modules():\n",
    "\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                #nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity=\"leaky_relu\")\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        out = self.layer7(out)\n",
    "        out = self.layer8(out)\n",
    "        out = self.layer9(out)\n",
    "        out = self.layer10(out)\n",
    "        out = self.layer11(out)\n",
    "        out = self.layer12(out)\n",
    "        out = self.layer13(out)\n",
    "        out = self.layer14(out)\n",
    "        out = self.layer15(out)\n",
    "        out = self.layer16(out)\n",
    "        out = self.layer17(out)\n",
    "        out = self.layer18(out)\n",
    "        out = self.layer19(out)\n",
    "        out = self.layer20(out)\n",
    "        out = self.layer21(out)\n",
    "        out = self.layer22(out)\n",
    "        out = self.layer23(out)\n",
    "        out = self.layer24(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = out.reshape((-1,7,7,((5)+num_classes)))\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T04:38:14.206863Z",
     "start_time": "2018-09-05T04:38:13.620185Z"
    }
   },
   "outputs": [],
   "source": [
    "def detection_loss_test(output, target):\n",
    "    # hyper parameter\n",
    "\n",
    "    lambda_coord = 5\n",
    "    lambda_noobj = 0.5\n",
    "\n",
    "    # check batch size\n",
    "    b, _, _, _ = target.shape\n",
    "\n",
    "    # class loss\n",
    "    MSE_criterion = nn.MSELoss()\n",
    "\n",
    "    # output tensor slice\n",
    "    objness1_output = output[:, :, :, 0]\n",
    "    x_offset1_output = output[:, :, :, 1]\n",
    "    y_offset1_output = output[:, :, :, 2]\n",
    "    width_ratio1_output = output[:, :, :, 3]\n",
    "    height_ratio1_output = output[:, :, :, 4]\n",
    "    class_output = output[:, :, :, 5]\n",
    "\n",
    "    # label tensor slice\n",
    "    objness_label = target[:, :, :, 0]\n",
    "    class_label = target[:, :, :, 1]\n",
    "    x_offset_label = target[:, :, :, 2]\n",
    "    y_offset_label = target[:, :, :, 3]\n",
    "    width_ratio_label = target[:, :, :, 4]\n",
    "    height_ratio_label = target[:, :, :, 5]\n",
    "    \n",
    "    noobjness_label = torch.neg(torch.add(objness_label, -1))\n",
    "    #y_one_hot = one_hot(class_output, class_label).cuda()\n",
    "\n",
    "    #print(y_one_hot)\n",
    "    #print(y_one_hot.shape)\n",
    "    #exit()\n",
    "\n",
    "    obj_coord1_loss = lambda_coord * \\\n",
    "                      torch.sum(objness_label *\n",
    "                                (torch.pow(x_offset1_output - x_offset_label, 2) +\n",
    "                                 torch.pow(y_offset1_output - y_offset_label, 2)))\n",
    "\n",
    "    obj_size1_loss = lambda_coord * \\\n",
    "                     torch.sum(objness_label *\n",
    "                               (torch.pow(width_ratio1_output - torch.sqrt(width_ratio_label), 2) +\n",
    "                                torch.pow(height_ratio1_output - torch.sqrt(height_ratio_label), 2)))\n",
    "\n",
    "    #obj_coord2_loss = lambda_coord * \\\n",
    "    #                  torch.sum(objness_label *\n",
    "    #                            (torch.pow(x_offset2_output - x_offset_label, 2) +\n",
    "    #                             torch.pow(y_offset2_output - y_offset_label, 2)))\n",
    "\n",
    "    #obj_size2_loss = lambda_coord * \\\n",
    "    #                 torch.sum(objness_label *\n",
    "    #                           (torch.pow(width_ratio2_output - torch.sqrt(width_ratio_label), 2) +\n",
    "    #                            torch.pow(height_ratio2_output - torch.sqrt(height_ratio_label), 2)))\n",
    "\n",
    "\n",
    "\n",
    "    obj_class_loss = torch.sum(objness_label * torch.pow(class_output - class_label, 2))\n",
    "\n",
    "    #noobj_class_loss = lambda_noobj * torch.sum(noobjness_label * MSE_criterion(class_output, y_one_hot))\n",
    "    \n",
    "    noobjness1_loss = lambda_noobj * torch.sum(noobjness_label * torch.pow(objness1_output - objness_label, 2))\n",
    "    #noobjness2_loss = lambda_noobj * torch.sum(objness_label * torch.pow(objness2_output - objness_label, 2))\n",
    "    \n",
    "    objness1_loss = torch.sum(objness_label * torch.pow(objness1_output - objness_label, 2))\n",
    "    #objness2_loss = torch.sum(objness_label * torch.pow(objness2_output - objness_label, 2))\n",
    "\n",
    "    #total_loss = (obj_coord1_loss + obj_size1_loss + obj_coord2_loss + obj_size2_loss + noobjness1_loss + noobjness2_loss +\n",
    "    #              obj_class_loss + objness1_loss + objness2_loss) / b\n",
    "    total_loss = (obj_coord1_loss + obj_size1_loss + noobjness1_loss  + objness1_loss + obj_class_loss) / b\n",
    "\n",
    "    #return total_loss, obj_coord1_loss, obj_size1_loss, obj_coord2_loss, obj_size2_loss, obj_class_loss, noobjness1_loss, noobjness2_loss, objness1_loss, objness2_loss\n",
    "    return total_loss, obj_coord1_loss / b, obj_size1_loss/ b, obj_class_loss/ b, noobjness1_loss/ b, objness1_loss/ b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Vidom on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T04:38:14.237845Z",
     "start_time": "2018-09-05T04:38:14.231834Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_vis_plot(_xlabel, _ylabel, _title, _legend):\n",
    "    return viz.line(\n",
    "        X=torch.zeros((1,)).cpu(),\n",
    "        Y=torch.zeros((1, 1)).cpu(),\n",
    "        opts=dict(\n",
    "            xlabel=_xlabel,\n",
    "            ylabel=_ylabel,\n",
    "            title=_title,\n",
    "            legend=_legend\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T04:38:14.345769Z",
     "start_time": "2018-09-05T04:38:14.342770Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_vis_plot(iteration, loss, window1, window2, update_type,\n",
    "                    epoch_size=1):\n",
    "    viz.line(\n",
    "        X=torch.ones((1, 1)).cpu() * iteration,\n",
    "        Y=torch.Tensor([loss]).unsqueeze(0).cpu() / epoch_size,\n",
    "        win=window1,\n",
    "        update=update_type\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T04:38:21.209858Z",
     "start_time": "2018-09-05T04:38:14.881463Z"
    }
   },
   "outputs": [],
   "source": [
    "import visdom\n",
    "viz = visdom.Visdom()\n",
    "\n",
    "vis_title = 'Yolo V1 Deepbaksu_vision (feat. martin, visionNoob) PyTorch on ' + 'VOC'\n",
    "vis_legend = ['Train Loss']\n",
    "\n",
    "iter_plot = yolov1.create_vis_plot(viz, 'Iteration', 'Total Loss', vis_title, vis_legend)\n",
    "\n",
    "coord1_plot = yolov1.create_vis_plot(viz, 'Iteration', 'coord1', vis_title, vis_legend)\n",
    "size1_plot = yolov1.create_vis_plot(viz, 'Iteration', 'size1', vis_title, vis_legend)\n",
    "\n",
    "#coord2_plot = yolov1.create_vis_plot(viz, 'Iteration', 'coord2', vis_title, vis_legend)\n",
    "#size2_plot = yolov1.create_vis_plot(viz, 'Iteration', 'size2', vis_title, vis_legend)\n",
    "\n",
    "noobjectness1_plot = yolov1.create_vis_plot(viz, 'Iteration', 'noobjectness1', vis_title, vis_legend)\n",
    "#noobjectness2_plot = yolov1.create_vis_plot(viz, 'Iteration', 'noobjectness2', vis_title, vis_legend)\n",
    "\n",
    "objectness1_plot = yolov1.create_vis_plot(viz, 'Iteration', 'objectness1', vis_title, vis_legend)\n",
    "#objectness2_plot = yolov1.create_vis_plot(viz, 'Iteration', 'objectness2', vis_title, vis_legend)\n",
    "\n",
    "obj_cls_plot = yolov1.create_vis_plot(viz, 'Iteration', 'obj_cls', vis_title, vis_legend)\n",
    "#noobj_cls_plot = yolov1.create_vis_plot(viz, 'Iteration', 'noobj_cls', vis_title, vis_legend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Device configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T04:38:21.478688Z",
     "start_time": "2018-09-05T04:38:21.234828Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_epochs = 16000\n",
    "num_classes = 1\n",
    "batch_size = 15\n",
    "learning_rate = 1e-3\n",
    "\n",
    "dropout_prop = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load VOC Pascal'12 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T04:38:30.207696Z",
     "start_time": "2018-09-05T04:38:21.505674Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH_MARTIN = \"/media/keti-ai/AI_HARD3/DataSets/VOC_Pascal/VOC/VOCdevkit/VOC2012\"\n",
    "DATASET_PATH_JAEWON = \"H:\\VOC\\VOC12\\VOCdevkit_2\\VOC2012\"\n",
    "SMALL_DATASET_PATH = \"D:/dataset/person-300\"\n",
    "train_dataset = VOC(root = SMALL_DATASET_PATH,\n",
    "                    transform=transforms.ToTensor(), cls_option = True, selective_cls=\"person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T04:38:30.241676Z",
     "start_time": "2018-09-05T04:38:30.237679Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True,\n",
    "                                           collate_fn=detection_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load YOLOv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T04:38:38.370027Z",
     "start_time": "2018-09-05T04:38:31.496959Z"
    }
   },
   "outputs": [],
   "source": [
    "net = yolov1.YOLOv1()\n",
    "# visualize_weights_distribution(net)\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T04:38:38.370027Z",
     "start_time": "2018-09-05T04:38:31.496959Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = YOLOv1().to(device)\n",
    "#model = torch.nn.DataParallel(net, device_ids=[0]).cuda()\n",
    "\n",
    "summary(model, (3, 448,448))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T04:38:38.370027Z",
     "start_time": "2018-09-05T04:38:31.496959Z"
    },
    "scrolled": true
   },
   "source": [
    "# Sanity Check for output dimention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T04:38:38.370027Z",
     "start_time": "2018-09-05T04:38:31.496959Z"
    }
   },
   "outputs": [],
   "source": [
    "images, labels = iter(train_loader).next()\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T04:38:38.370027Z",
     "start_time": "2018-09-05T04:38:31.496959Z"
    }
   },
   "outputs": [],
   "source": [
    "#for just a image\n",
    "num = 2\n",
    "test_image = images[num]\n",
    "outputs = model(torch.cuda.FloatTensor(np.expand_dims(test_image,axis=0)))\n",
    "print(outputs.shape)\n",
    "\n",
    "#for images (batch size)\n",
    "outputs = model(torch.cuda.FloatTensor(images))\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T04:38:38.370027Z",
     "start_time": "2018-09-05T04:38:31.496959Z"
    }
   },
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1e-5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T04:38:38.370027Z",
     "start_time": "2018-09-05T04:38:31.496959Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.optim.Adam?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T04:41:57.690170Z",
     "start_time": "2018-09-05T04:41:57.451922Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    if (epoch == 200) or (epoch == 400) or (epoch == 600) or (epoch == 20000) or (epoch == 30000):\n",
    "        scheduler.step()\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "    \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calc Loss\n",
    "        loss, \\\n",
    "        obj_coord1_loss, \\\n",
    "        obj_size1_loss, \\\n",
    "        obj_class_loss, \\\n",
    "        noobjness1_loss, \\\n",
    "        objness1_loss = detection_loss_test(outputs, labels)\n",
    "        #objness2_loss = yolov1.detection_loss(outputs, labels)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 10 == 0:\n",
    "            \n",
    "            print('Epoch ,[{}/{}] ,Step ,[{}/{}] ,lr ,{} ,total_loss ,{:.4f} ,coord1 ,{} ,size1 ,{} ,noobj_clss ,{} ,objness1 ,{} ,'\n",
    "                  .format(epoch + 1,\n",
    "                          num_epochs,\n",
    "                          i + 1,\n",
    "                          total_step,\n",
    "                          [param_group['lr'] for param_group in optimizer.param_groups],\n",
    "                          loss.item(),\n",
    "                          obj_coord1_loss,\n",
    "                          obj_size1_loss,\n",
    "                          obj_class_loss,\n",
    "                          noobjness1_loss,\n",
    "                          objness1_loss\n",
    "                          ))\n",
    "            \n",
    "\n",
    "            yolov1.update_vis_plot(viz, (epoch+1)*batch_size +(i + 1), loss.item(), iter_plot, None, 'append')\n",
    "            yolov1.update_vis_plot(viz, (epoch + 1) * batch_size + (i + 1), obj_coord1_loss, coord1_plot, None, 'append')\n",
    "            yolov1.update_vis_plot(viz, (epoch + 1) * batch_size + (i + 1), obj_size1_loss, size1_plot, None, 'append')\n",
    "            yolov1.update_vis_plot(viz, (epoch + 1) * batch_size + (i + 1), obj_class_loss, obj_cls_plot, None, 'append')\n",
    "            yolov1.update_vis_plot(viz, (epoch + 1) * batch_size + (i + 1), noobjness1_loss, noobjectness1_plot, None, 'append')\n",
    "            yolov1.update_vis_plot(viz, (epoch + 1) * batch_size + (i + 1), objness1_loss, objectness1_plot, None, 'append')\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "    if (epoch % 300) == 0:\n",
    "        yolov1.save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': \"YOLOv1\",\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, False, filename='checkpoint_{}.pth.tar'.format(epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_output = outputs[:, :, :, 10:]\n",
    "class_label = labels[:, :, :, 1]\n",
    "y_one_hot = one_hot(class_output, class_label)\n",
    "y_one_hot[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class_output[0])\n",
    "print(class_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label/shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objness_label = labels[:, :, :, 0]\n",
    "noobjness_label = torch.neg(torch.add(objness_label, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noobjness_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc Loss\n",
    "loss, \\\n",
    "obj_coord1_loss, \\\n",
    "obj_size1_loss, \\\n",
    "obj_class_loss, \\\n",
    "noobj_class_loss, \\\n",
    "objness1_loss = detection_loss_test(outputs, labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total loss:\\t\\t\",loss)\n",
    "print(\"obj_coord1_loss:\\t\",obj_coord1_loss)\n",
    "print(\"obj_size1_loss:\\t\\t\",obj_size1_loss)\n",
    "print(\"obj_class_loss:\\t\\t\",obj_class_loss)\n",
    "print(\"noobj_class_loss:\\t\",noobj_class_loss)\n",
    "print(\"objness1_loss:\\t\\t\",objness1_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width_ratio1_output = outputs[:, :, :, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.sqrt(width_ratio1_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(width_ratio1_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True,\n",
    "                                           collate_fn=detection_collate)\n",
    "\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[0, :, :, 0])\n",
    "print(outputs[0, :, :, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[0,0,0,:])\n",
    "print(outputs[1,0,0,:])\n",
    "print(outputs[2,0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.transpose(images[num],(1,2,0)))\n",
    "plt.show()\n",
    "plt.imshow(outputs.detach().cpu().numpy()[0,:, :, 0])\n",
    "plt.show()\n",
    "plt.imshow(outputs.detach().cpu().numpy()[0,:, :, 5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expand_dims(test_image,axis=0).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
